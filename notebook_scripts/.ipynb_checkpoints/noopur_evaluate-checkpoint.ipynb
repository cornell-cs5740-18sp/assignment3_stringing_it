{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-8ccc37bb1b4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    194\u001b[0m     \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mtest_predictions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpos_tagger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minference\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[0;31m# Write them to a file to update the leaderboard\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'NoneType' object is not iterable"
     ]
    }
   ],
   "source": [
    "\"\"\" Contains the part of speech tagger class. \"\"\"\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "from collections import defaultdict\n",
    "def make_sentences(tokens,tags):\n",
    "    \"\"\"\n",
    "    Function converts list of words into sentences with sentences of corresponding tags\n",
    "\n",
    "    INPUT : Dataframe of tokens, Dataframe of tags\n",
    "\n",
    "    OUTPUT : Zip of list of sentences, list of tags sentences\n",
    "    \"\"\"\n",
    "    data = tokens.join(tags, on=\"id\", how = \"inner\", rsuffix = \"_tag\").drop(\"id_tag\",axis=1)\n",
    "    sentences = []\n",
    "    tags_list = []\n",
    "    temp_tokens = []\n",
    "    temp_tags = []\n",
    "    for row in data.itertuples():\n",
    "        word = row[2]\n",
    "        tag = row[3]\n",
    "        if word!='-DOCSTART-' and word!='.':\n",
    "            temp_tokens.append(word)\n",
    "            temp_tags.append(tag)\n",
    "        if word=='.':\n",
    "            sentences.append(' '.join(temp_tokens) + ' .')\n",
    "            tags_list.append(' '.join(temp_tags) + ' .')\n",
    "            temp_tokens = []\n",
    "            temp_tags = []\n",
    "\n",
    "    return zip(sentences,tags)\n",
    "\n",
    "def load_data(sentence_file, tag_file=None):\n",
    "    \"\"\"Loads data from two files: one containing sentences and one containing tags.\n",
    "\n",
    "    tag_file is optional, so this function can be used to load the test data.\n",
    "\n",
    "    Suggested to split the data by the document-start symbol.\n",
    "\n",
    "    \"\"\"\n",
    "    tokens = pd.read_csv(sentence_file)\n",
    "    if tag_file:\n",
    "        tags = pd.read_csv(tag_file)\n",
    "    else:\n",
    "        #dummy tags for test file\n",
    "        tags = pd.DataFrame()\n",
    "        tags['id'] = range(len(tokens))\n",
    "        tags['tag'] = ['NNP']*len(tokens)\n",
    "\n",
    "    return make_sentences(tokens,tags)\n",
    "\n",
    "def evaluate(data, model):\n",
    "    \"\"\"Evaluates the POS model on some sentences and gold tags.\n",
    "\n",
    "    This model can compute a few different accuracies:\n",
    "        - whole-sentence accuracy\n",
    "        - per-token accuracy\n",
    "        - compare the probabilities computed by different styles of decoding\n",
    "\n",
    "    You might want to refactor this into several different evaluation functions.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "class POSTagger():\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the tagger model parameters and anything else necessary. \"\"\"\n",
    "        self.sentences = []\n",
    "        self.tags_sentences = []\n",
    "        self.unitag = {}\n",
    "        self.bitag = {}\n",
    "        self.tritag = {}\n",
    "        self.wordtag = {}\n",
    "        self.tag_set = set()\n",
    "\n",
    "    def nGramTagger(self,n):\n",
    "        \"\"\"\n",
    "        Computes n-gram tag count dictionary for estimating transition probabilitites\n",
    "        INPUT : int (n)\n",
    "        OUTPUT Dict (n-gram tag count dictionary)\n",
    "        \"\"\"\n",
    "        dic = {}\n",
    "        for line in self.tags_sentences:\n",
    "            line = line.split(' ')\n",
    "            line = ['*']*n + line\n",
    "            for i in range(n,len(line)):\n",
    "                if n==1:\n",
    "                    item = line[i]\n",
    "                else:\n",
    "                    item = tuple(line[i-n:i])\n",
    "                if item in dic:\n",
    "                    dic[item]+=1\n",
    "                else:\n",
    "                    dic[item]=1\n",
    "        return dic\n",
    "\n",
    "    def wordTagger(self):\n",
    "        \"\"\"\n",
    "        Computes word,tag count dictionary for estimating emission probabilitites\n",
    "        INPUT : None\n",
    "        OUTPUT : Dict ((word,tag) count dictionary)\n",
    "        \"\"\"\n",
    "\n",
    "        dic = defaultdict(int)\n",
    "        for line1,line2 in zip(self.sentences,self.tags_sentences):\n",
    "            for word,tag in zip(line1.split(' '),line2.split(' ')):\n",
    "                dic[(word,tag)]+=1\n",
    "        return dic\n",
    "\n",
    "    def get_q(self,tag_penult,tag_last,tag_current):\n",
    "        \"\"\"\n",
    "        Computes transition probabilitites for trigram tagger\n",
    "        INPUT : (current tag, previous tag, penultimate tag) || (string, string, string)\n",
    "        OUTPUT : (transition probabilty) || (float)\n",
    "        \"\"\"\n",
    "\n",
    "        return float(self.tritag[(tag_penult, tag_last, tag_current)])/self.bitag[(tag_penult, tag_last)]\n",
    "\n",
    "    def get_e(self,word,tag):\n",
    "        \"\"\"\n",
    "        Computes emission probabilitites for trigram tagger\n",
    "        INPUT : (word, tag) || (string, string)\n",
    "        OUTPUT : (emission probabilty) || (float)\n",
    "        \"\"\"\n",
    "\n",
    "        return float(self.wordtag[(word,tag)])/self.unitag[tag]\n",
    "\n",
    "    def train(self, data):\n",
    "        \"\"\"Trains the model by computing transition and emission probabilities.\n",
    "\n",
    "        You should also experiment:\n",
    "            - smoothing.\n",
    "            - N-gram models with varying N.\n",
    "\n",
    "        \"\"\"\n",
    "        self.sentences = zip(*data)[0]\n",
    "        self.tags_sentences = zip(*data)[1]\n",
    "\n",
    "        #create dictionaries of counts of uni, bi and tri tags\n",
    "        self.unitag = self.nGramTagger(1)\n",
    "        self.bitag = self.nGramTagger(2)\n",
    "        self.tritag = self.nGramTagger(3)\n",
    "\n",
    "        self.wordtag = self.wordTagger()\n",
    "        self.tag_set = set(self.unitag.keys())\n",
    "\n",
    "\n",
    "    def sequence_probability(self, sequence, tags):\n",
    "        \"\"\"Computes the probability of a tagged sequence given the emission/transition\n",
    "        probabilities.\n",
    "        \"\"\"\n",
    "        tag_penult = '*'\n",
    "        tag_prev = '*'\n",
    "        prod = 1\n",
    "        for word, tag in zip(sequence,tags):\n",
    "            q = self.get_q(tag,tag_prev,tag_penult)\n",
    "            e = self.get_e(word,tag)\n",
    "            tag_penult = tag_prev\n",
    "            tag_prev = tagger\n",
    "            prod *= q*e\n",
    "\n",
    "        return prod\n",
    "    \n",
    "    # Get list of possible tags at position k\n",
    "    def S(k):\n",
    "        if k in (-1, 0):\n",
    "            return set('*')\n",
    "        else:\n",
    "            return self.tag_set\n",
    "        \n",
    "    def inference(self, sentence):\n",
    "        \"\"\"Tags a sequence with part of speech tags.\n",
    "\n",
    "        You should implement different kinds of inference (suggested as separate\n",
    "        methods):\n",
    "\n",
    "            - greedy decoding\n",
    "            - decoding with beam search\n",
    "            - viterbi\n",
    "        \"\"\"\n",
    "        pi_func = defaultdict(float)\n",
    "        pi_func[(0, '*', '*')] = 0.0\n",
    "        \n",
    "        n = len(sentence)\n",
    "        sentence = sentence.split(\" \")\n",
    "        for k in range(1,n+1):\n",
    "            for u in S(k-1):\n",
    "                for v in S(k):\n",
    "                    max_score = float('-Inf')\n",
    "                    for w in S(k - 2):\n",
    "                        score = pi_func.get((k-1, w, u),float('-Inf')) * get_q(w,u,v) * e(sentence[k],v)\n",
    "                        if score > max_score:\n",
    "                            max_score = score\n",
    "                    pi_func[(k, u, v)] = max_score\n",
    "        \n",
    "        \n",
    "        return tag_sequence\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    pos_tagger = POSTagger()\n",
    "\n",
    "    train_data = load_data(\"../data/train_x.csv\", \"../data/train_y.csv\")\n",
    "    dev_data = load_data(\"../data/dev_x.csv\", \"../data/dev_y.csv\")\n",
    "    test_data = load_data(\"../data/test_x.csv\")\n",
    "\n",
    "    pos_tagger.train(train_data)\n",
    "\n",
    "    # Experiment with your decoder using greedy decoding, beam search, viterbi...\n",
    "\n",
    "    # Here you can also implement experiments that compare different styles of decoding,\n",
    "    # smoothing, n-grams, etc.\n",
    "    evaluate(dev_data, pos_tagger)\n",
    "\n",
    "    # Predict tags for the test set\n",
    "    test_predictions = []\n",
    "    for sentence in test_data:\n",
    "        test_predictions.extend(pos_tagger.inference(sentence))\n",
    "\n",
    "    # Write them to a file to update the leaderboard\n",
    "    # TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
